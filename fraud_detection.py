# -*- coding: utf-8 -*-
"""Fraud_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g2Y0FhSgIj1dEzBXNax-xP7QzcorKmmQ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
import tensorflow as tf
from tensorflow.keras.layers import Dense

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Fraud.csv")

df.head(10)

df.info()

df.describe()

df['newbalanceDest'] = df['newbalanceDest'].fillna(method = 'ffill')
df['isFraud'] = df['isFraud'].fillna(method = 'ffill')
df['isFlaggedFraud'] = df['isFlaggedFraud'].fillna(method = 'ffill')

df.info()

sns.countplot(x = 'type', data = df)

df['isFraud'].value_counts()

df['isFlaggedFraud'].value_counts()

sns.countplot(x = 'isFraud', data = df)
print("1.0: Transaction is Fraud \n0.0: Transaction is legit")

sns.scatterplot(x = 'oldbalanceOrg', y = 'newbalanceOrig', data = df, hue = 'isFraud')

sns.scatterplot(x = 'oldbalanceDest', y = 'newbalanceDest', data = df, hue = 'isFraud')

sns.violinplot(x = 'newbalanceDest', data = df)

sns.violinplot(x = 'oldbalanceDest', data = df)

df.columns

new_type = pd.get_dummies(df['type'], dtype = int)

df1 = pd.DataFrame(new_type)

df = pd.concat([df,df1], axis = 1)

df

df = df.drop('type', axis = 1)

df.head(10)

X = df.drop({'isFraud', 'nameOrig', 'nameDest'}, axis = 1)
y = df[['isFraud']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

print(X_train)
print(X_test)
print(y_train)
print(y_test)

scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.fit_transform(X_test)

tf.random.set_seed(42)
classifier_model = tf.keras.models.Sequential()
classifier_model.add(tf.keras.layers.Dense(units = 100, activation = 'relu', input_shape = (12,)))
classifier_model.add(tf.keras.layers.Dropout(0.3))
classifier_model.add(tf.keras.layers.Dense(units = 50, activation = 'relu'))
classifier_model.add(tf.keras.layers.Dropout(0.3))
classifier_model.add(tf.keras.layers.Dense(units = 50, activation = 'relu'))
classifier_model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))

classifier_model.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = 'accuracy')

#calculating the epochs on training and validation dataset
from tensorflow.keras.callbacks import EarlyStopping
Early_Stop = EarlyStopping()
epochs_hist = classifier_model.fit(X_train_scaled,y_train,epochs = 5, validation_data = (X_test_scaled, y_test), batch_size = 125, callbacks=[Early_Stop])

import keras
keras.utils.plot_model(classifier_model,show_shapes=True)

hist = classifier_model.history.history
new_hist = pd.DataFrame(hist)
new_hist.plot()

#evaluating the model on the testing dataset.
evaluation = classifier_model.evaluate(X_test,y_test)
print('test accuracy:{}'.format(evaluation[1]))

y_test_predict = classifier_model.predict(X_test)
y_train_predict = classifier_model.predict(X_train)
y_test_predict = y_test_predict > 0.5
y_train_predict = y_train_predict > 0.5

from sklearn.metrics import confusion_matrix, classification_report
cm = confusion_matrix(y_train_predict, y_train)
cm2 = confusion_matrix(y_test_predict, y_test)

sns.heatmap(cm, annot = True)

sns.heatmap(cm2, annot = True)

print("Training Report:\n", classification_report(y_train_predict, y_train))
print("Testing Report:\n", classification_report(y_test_predict, y_test))

